{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating synthetic corruption\n",
    "\n",
    "There doesn't seem to be enough examples of corrupted data to train models\n",
    "\n",
    "- part 1 learns the transmission distributions for the corruption model\n",
    "- part 2 applies the corruption to text\n",
    "- part 3 creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from corruption import *\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/aligned/aligned_BLN600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_aligned_list = data['gt_aligned'].to_list()\n",
    "\n",
    "noise_aligned_list = data['noise_aligned'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example aligned text pairs\n",
    "aligned_texts = [\n",
    "    (\"New Yo@rk is big\", \"Nev Yo rk@is@@@\"),\n",
    "    (\"New Yo@rk is big\", \"New Yo rk@is@@@@\"),\n",
    "    # Add more aligned text pairs here\n",
    "]\n",
    "\n",
    "aligned_texts = list(zip(gt_aligned_list, noise_aligned_list))\n",
    "\n",
    "# Initialize counters\n",
    "deletion_counts, insertion_counts, substitution_counts, character_counts = initialize_counters()\n",
    "\n",
    "# Update counts for all aligned text pairs\n",
    "for gt, noise in aligned_texts:\n",
    "    update_counts(gt, noise, deletion_counts, insertion_counts, substitution_counts, character_counts)\n",
    "\n",
    "# Calculate character distribution\n",
    "character_distribution = calculate_character_distribution(character_counts)\n",
    "\n",
    "# Calculate conditional probabilities\n",
    "conditional_probs = calculate_conditional_probs(deletion_counts, insertion_counts, substitution_counts, character_counts)\n",
    "\n",
    "# Generate substitution and insertion tables\n",
    "substitution_table, insertion_table = generate_substitution_insertion_tables(substitution_counts, insertion_counts, character_counts)\n",
    "\n",
    "# Add default values to tables\n",
    "conditional_probs, substitution_table, insertion_table = add_default_values(conditional_probs, substitution_table, insertion_table, character_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076\n",
      "2320\n",
      "1821\n",
      "103661\n"
     ]
    }
   ],
   "source": [
    "print(deletion_counts['a'])\n",
    "print(sum(substitution_counts['a'].values()))\n",
    "print(sum(insertion_counts['a'].values()))\n",
    "print(character_counts['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count2 = character_counts[char]\n",
    "\n",
    "# Calculate individual probabilities for this character\n",
    "delete_prob2 = deletion_counts[char] / total_count2 if char in deletion_counts else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deletion_counts['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 0.9313472083726387,\n",
       " 'substitute': 0.02592342906843265,\n",
       " 'delete': 0.015011386401281067,\n",
       " 'insert': 0.029770339845345932}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_joint_probabilities(conditional_probs, character_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 0.8382124875353749,\n",
       " 'substitute': 0.05781538406622265,\n",
       " 'delete': 0.03309549012525023,\n",
       " 'insert': 0.07087663827315206}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probs2 = modify_and_renormalize_probs(conditional_probs, column = 'correct', factor = .9)\n",
    "\n",
    "calculate_joint_probabilities(conditional_probs2, character_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def load_encyc_brit(file_path):\n",
    "    \"\"\"\n",
    "    Reads a text file and splits it into sections based on at least three line breaks.\n",
    "    Extracts the title from each section based on the text in all caps before the first comma\n",
    "    or any text in brackets. Returns a DataFrame where each section is a row with 'Title' and 'Section' columns.\n",
    "    \n",
    "    :param file_path: Path to the text file\n",
    "    :return: DataFrame with titles and sections as rows\n",
    "    \"\"\"\n",
    "    # Step 1: Read the text file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    text = re.sub(r'\\n{3}PLATE.*?\\]\\n{3}', '', text, flags=re.DOTALL)\n",
    "    #remove illustrations and the surrounding line breaks\n",
    "    text = re.sub(r'\\n*\\[Illustration:.*?\\]\\n*', '', text, flags=re.DOTALL)\n",
    "    #Deal with subsections by removing \n",
    "    text = re.sub(r'\\n{1,}(\\s{2,}.*\\n)', r'\\n\\1', text)\n",
    "\n",
    "    # Step 2: Split the text into sections based on at least three line breaks\n",
    "    sections = re.split(r'\\n{3,}', text)\n",
    "\n",
    "    # Step 3: Extract titles and create DataFrame rows\n",
    "    data = []\n",
    "    for section in sections:\n",
    "        # Optional: Strip leading/trailing whitespace\n",
    "        section = section.strip()\n",
    "        if not section:\n",
    "            continue\n",
    "        \n",
    "        # Step 3a: Extract the title (text in all caps before the first comma or bracketed text)\n",
    "        match = re.match(r'^([A-Z\\s]+?)(?:\\s*\\([^)]*\\))?(?:,|$)', section)\n",
    "        if match:\n",
    "            title = match.group(1).strip()\n",
    "        else:\n",
    "            title = None  # If no title is found, set it to None or an empty string\n",
    "\n",
    "        # Step 3b: Store the section and title\n",
    "        data.append({'title': title, 'content': section})\n",
    "\n",
    "    # Step 4: Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vols = os.listdir('./data/encyclopedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pg41264.txt',\n",
       " 'pg39908.txt',\n",
       " 'pg34612.txt',\n",
       " 'pg34018.txt',\n",
       " 'pg37064.txt',\n",
       " 'pg32758.txt',\n",
       " 'pg39232.txt',\n",
       " 'pg38454.txt',\n",
       " 'pg37282.txt',\n",
       " 'pg37880.txt',\n",
       " 'pg39775.txt',\n",
       " 'pg40641.txt',\n",
       " 'pg37610.txt',\n",
       " 'pg43427.txt',\n",
       " 'pg31793.txt',\n",
       " 'pg19699.txt',\n",
       " 'pg38892.txt',\n",
       " 'pg31447.txt',\n",
       " 'pg40956.txt',\n",
       " 'pg35092.txt',\n",
       " 'pg34162.txt',\n",
       " 'pg34878.txt',\n",
       " 'pg35925.txt',\n",
       " 'pg40370.txt',\n",
       " 'pg33127.txt',\n",
       " 'pg38622.txt',\n",
       " 'pg30073.txt',\n",
       " 'pg39521.txt',\n",
       " 'pg36104.txt',\n",
       " 'pg35398.txt',\n",
       " 'pg33698.txt',\n",
       " 'pg34992.txt',\n",
       " 'pg32940.txt',\n",
       " 'pg32097.txt',\n",
       " 'pg42342.txt',\n",
       " 'pg34702.txt',\n",
       " 'pg32860.txt',\n",
       " 'pg40156.txt',\n",
       " 'pg38143.txt',\n",
       " 'pg35236.txt',\n",
       " 'pg39029.txt',\n",
       " 'pg40009.txt',\n",
       " 'pg39127.txt',\n",
       " 'pg38964.txt',\n",
       " 'pg41343.txt',\n",
       " 'pg41567.txt',\n",
       " 'pg39632.txt',\n",
       " 'pg32783.txt',\n",
       " 'pg33052.txt',\n",
       " 'pg37806.txt',\n",
       " 'pg39700.txt',\n",
       " 'pg39353.txt',\n",
       " 'pg37160.txt',\n",
       " 'pg31641.txt',\n",
       " 'pg31329.txt',\n",
       " 'pg36735.txt',\n",
       " 'pg41472.txt',\n",
       " 'pg30935.txt',\n",
       " 'pg33614.txt',\n",
       " 'pg34312.txt',\n",
       " 'pg33239.txt',\n",
       " 'pg35606.txt',\n",
       " 'pg42736.txt',\n",
       " 'pg42552.txt',\n",
       " 'pg33189.txt',\n",
       " 'pg35561.txt',\n",
       " 'pg40538.txt',\n",
       " 'pg41685.txt',\n",
       " 'pg27479.txt',\n",
       " 'pg37461.txt',\n",
       " 'pg34116.txt',\n",
       " 'pg34047.txt',\n",
       " 'pg33750.txt',\n",
       " 'pg41902.txt',\n",
       " 'pg38202.txt',\n",
       " 'pg37736.txt',\n",
       " 'pg35306.txt',\n",
       " 'pg38304.txt',\n",
       " 'pg32607.txt',\n",
       " 'pg41156.txt',\n",
       " 'pg31855.txt',\n",
       " 'pg42854.txt',\n",
       " 'pg31950.txt',\n",
       " 'pg32063.txt',\n",
       " 'pg35169.txt',\n",
       " 'pg19846.txt',\n",
       " 'pg36226.txt',\n",
       " 'pg43060.txt',\n",
       " 'pg43254.txt',\n",
       " 'pg34405.txt',\n",
       " 'pg40096.txt',\n",
       " 'pg33427.txt',\n",
       " 'pg37523.txt',\n",
       " 'pg34751.txt',\n",
       " 'pg38799.txt',\n",
       " 'pg35473.txt',\n",
       " 'pg34082.txt',\n",
       " 'pg36452.txt',\n",
       " 'pg32975.txt',\n",
       " 'pg32689.txt',\n",
       " 'pg34209.txt',\n",
       " 'pg40863.txt',\n",
       " 'pg27478.txt',\n",
       " 'pg39435.txt',\n",
       " 'pg41773.txt',\n",
       " 'pg27480.txt',\n",
       " 'pg40769.txt',\n",
       " 'pg31156.txt',\n",
       " 'pg33295.txt',\n",
       " 'pg32294.txt',\n",
       " 'pg38709.txt',\n",
       " 'pg33550.txt',\n",
       " 'pg38539.txt',\n",
       " 'pg42173.txt',\n",
       " 'pg32423.txt',\n",
       " 'pg38401.txt',\n",
       " 'pg42638.txt',\n",
       " 'pg35747.txt',\n",
       " 'pg13600.txt',\n",
       " 'pg42048.txt',\n",
       " 'pg30685.txt',\n",
       " 'pg41055.txt',\n",
       " 'pg33365.txt',\n",
       " 'pg34533.txt',\n",
       " 'pg37984.txt',\n",
       " 'pg200.txt',\n",
       " 'pg32182.txt']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pg33239.txt'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vols[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAT</td>\n",
       "      <td>CAT,[1] properly the name of the well-known do...</td>\n",
       "      <td>4255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>FOOTNOTE:\\n\\n  [1] The word \"cat\" is applied t...</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CATABOLISM</td>\n",
       "      <td>CATABOLISM, or KATABOLISM (Gr. [Greek: kata], ...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CATACLYSM</td>\n",
       "      <td>CATACLYSM (Gr. [Greek: kataklusmos], a deluge)...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CATACOMB</td>\n",
       "      <td>CATACOMB, a subterranean excavation for the in...</td>\n",
       "      <td>14780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>CELT</td>\n",
       "      <td>CELT, or KELT, the generic name of an ancient ...</td>\n",
       "      <td>3176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>None</td>\n",
       "      <td>CELTIC LANGUAGES\\n\\nIntroduction.--The Celtic ...</td>\n",
       "      <td>29337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>None</td>\n",
       "      <td>CELTIC LITERATURE\\n\\n  Ogam inscriptions.\\n\\nI...</td>\n",
       "      <td>68642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>None</td>\n",
       "      <td>FOOTNOTES:\\n  [1] J. Loth gives it as his opin...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>CELT</td>\n",
       "      <td>CELT, a word in common use among British and F...</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          title                                            content  tokens\n",
       "5           CAT  CAT,[1] properly the name of the well-known do...    4255\n",
       "6          None  FOOTNOTE:\\n\\n  [1] The word \"cat\" is applied t...     607\n",
       "7    CATABOLISM  CATABOLISM, or KATABOLISM (Gr. [Greek: kata], ...      62\n",
       "8     CATACLYSM  CATACLYSM (Gr. [Greek: kataklusmos], a deluge)...      80\n",
       "9      CATACOMB  CATACOMB, a subterranean excavation for the in...   14780\n",
       "..          ...                                                ...     ...\n",
       "208        CELT  CELT, or KELT, the generic name of an ancient ...    3176\n",
       "209        None  CELTIC LANGUAGES\\n\\nIntroduction.--The Celtic ...   29337\n",
       "210        None  CELTIC LITERATURE\\n\\n  Ogam inscriptions.\\n\\nI...   68642\n",
       "211        None  FOOTNOTES:\\n  [1] J. Loth gives it as his opin...     144\n",
       "212        CELT  CELT, a word in common use among British and F...     802\n",
       "\n",
       "[208 rows x 3 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage:\n",
    "file_path =os.path.join('data/encyclopedia',all_vols[60]) #'data/encyclopedia/pg31447.txt' \n",
    "df = load_encyc_brit(file_path)\n",
    "df['content'] = df['content'].str.replace(\"_\", \"\")\n",
    "df['tokens'] = df['content'].apply(lambda text: len(tokenizer.encode(text)))\n",
    "start_row = (df['content'].str.contains(\"ARTICLES IN THIS SLICE\", na=False).idxmax()+1)\n",
    "end_row = (df['content'].str.contains(\"END OF THE PROJECT GUTENBERG EBOOK\", na=False).idxmax()-1)\n",
    "\n",
    "df = df.loc[start_row:end_row, :]\n",
    "df#.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 127/127 [01:36<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "encyc_df = []\n",
    "\n",
    "# Loop through each file in the list with tqdm for progress monitoring\n",
    "for file_path in tqdm(all_vols, desc=\"Processing Files\"):\n",
    "    # Construct the full file path\n",
    "    full_path = os.path.join('data/encyclopedia', file_path)\n",
    "    \n",
    "    # Load the data into a DataFrame\n",
    "    df = load_encyc_brit(full_path)\n",
    "    \n",
    "    # Replace underscores in the content\n",
    "    df['content'] = df['content'].str.replace(\"_\", \"\")\n",
    "    \n",
    "    # Calculate the number of tokens for each row\n",
    "    df['tokens'] = df['content'].apply(lambda text: len(tokenizer.encode(text)))\n",
    "\n",
    "    df['file'] = file_path\n",
    "    \n",
    "    # Find the start and end rows\n",
    "    start_row = df['content'].str.contains(\"ARTICLES IN THIS SLICE\", na=False).idxmax() + 1\n",
    "    end_row = df['content'].str.contains(\"END OF THE PROJECT GUTENBERG EBOOK\", na=False).idxmax() - 1\n",
    "    \n",
    "    # Slice the DataFrame to include only relevant rows\n",
    "    df = df.iloc[start_row:end_row]\n",
    "    \n",
    "    # Append the processed DataFrame to the list\n",
    "    encyc_df.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "encyc_df = pd.concat(encyc_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JACOBITES</td>\n",
       "      <td>JACOBITES (from Lat. Jacobus, James), the name...</td>\n",
       "      <td>1673</td>\n",
       "      <td>pg41264.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JACOBS</td>\n",
       "      <td>JACOBS, CHRISTIAN FRIEDRICH WILHELM (1764-1847...</td>\n",
       "      <td>450</td>\n",
       "      <td>pg41264.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JACOBS CAVERN</td>\n",
       "      <td>JACOBS CAVERN, a cavern in latitude 36° 35´ N....</td>\n",
       "      <td>859</td>\n",
       "      <td>pg41264.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JACOBSEN</td>\n",
       "      <td>JACOBSEN, JENS PETER (1847-1885), Danish imagi...</td>\n",
       "      <td>657</td>\n",
       "      <td>pg41264.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>JACOB'S WELL, the scene of the conversation be...</td>\n",
       "      <td>333</td>\n",
       "      <td>pg41264.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21881</th>\n",
       "      <td>COSTUME</td>\n",
       "      <td>COSTUME (through the Fr. costume, from Ital. c...</td>\n",
       "      <td>2556</td>\n",
       "      <td>pg32182.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21882</th>\n",
       "      <td>None</td>\n",
       "      <td>I. ANCIENT COSTUME\\n\\ni. Ancient Oriental.--Al...</td>\n",
       "      <td>18173</td>\n",
       "      <td>pg32182.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21883</th>\n",
       "      <td>None</td>\n",
       "      <td>II. COSTUME IN MEDIEVAL AND MODERN EUROPE\\n\\ni...</td>\n",
       "      <td>16034</td>\n",
       "      <td>pg32182.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21884</th>\n",
       "      <td>None</td>\n",
       "      <td>III. NATIONAL AND CLASS COSTUME\\n\\nCostume, as...</td>\n",
       "      <td>1865</td>\n",
       "      <td>pg32182.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21885</th>\n",
       "      <td>None</td>\n",
       "      <td>IV. OFFICIAL COSTUME\\n\\nOfficial costumes, in ...</td>\n",
       "      <td>3194</td>\n",
       "      <td>pg32182.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21886 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                            content  \\\n",
       "0          JACOBITES  JACOBITES (from Lat. Jacobus, James), the name...   \n",
       "1             JACOBS  JACOBS, CHRISTIAN FRIEDRICH WILHELM (1764-1847...   \n",
       "2      JACOBS CAVERN  JACOBS CAVERN, a cavern in latitude 36° 35´ N....   \n",
       "3           JACOBSEN  JACOBSEN, JENS PETER (1847-1885), Danish imagi...   \n",
       "4               None  JACOB'S WELL, the scene of the conversation be...   \n",
       "...              ...                                                ...   \n",
       "21881        COSTUME  COSTUME (through the Fr. costume, from Ital. c...   \n",
       "21882           None  I. ANCIENT COSTUME\\n\\ni. Ancient Oriental.--Al...   \n",
       "21883           None  II. COSTUME IN MEDIEVAL AND MODERN EUROPE\\n\\ni...   \n",
       "21884           None  III. NATIONAL AND CLASS COSTUME\\n\\nCostume, as...   \n",
       "21885           None  IV. OFFICIAL COSTUME\\n\\nOfficial costumes, in ...   \n",
       "\n",
       "       tokens         file  \n",
       "0        1673  pg41264.txt  \n",
       "1         450  pg41264.txt  \n",
       "2         859  pg41264.txt  \n",
       "3         657  pg41264.txt  \n",
       "4         333  pg41264.txt  \n",
       "...       ...          ...  \n",
       "21881    2556  pg32182.txt  \n",
       "21882   18173  pg32182.txt  \n",
       "21883   16034  pg32182.txt  \n",
       "21884    1865  pg32182.txt  \n",
       "21885    3194  pg32182.txt  \n",
       "\n",
       "[21886 rows x 4 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encyc_df#['tokens'].sum()/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(107274)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encyc_df.loc[encyc_df['tokens']<100,'tokens'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10604916)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[~df['title'].isnull() & (df.index>7), 'tokens'].sum()*126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def text_to_dataframe_with_titles(file_path):\n",
    "    \"\"\"\n",
    "    Reads a text file and splits it into sections based on double line breaks and titles.\n",
    "    Returns a DataFrame with each section's title and content.\n",
    "    \n",
    "    :param file_path: Path to the text file\n",
    "    :return: DataFrame with titles and content\n",
    "    \"\"\"\n",
    "    # Step 1: Read the text file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Step 2: Split the text into sections based on double line breaks\n",
    "    sections = text.split('\\n\\n\\n')\n",
    "    \n",
    "    # Step 3: Process each section to extract title and content\n",
    "    data = []\n",
    "    for section in sections:\n",
    "        # Use regex to find the title which is enclosed in underscores\n",
    "        match = re.search(r'_(.+)_\\n\\n', section)\n",
    "        if match:\n",
    "            title = match.group(1).strip()\n",
    "            content = section.replace(match.group(0), '').strip()  # Remove the title from content\n",
    "        else:\n",
    "            title = None\n",
    "            content = section.strip()\n",
    "\n",
    "        if content:  # Ensure the content is not empty\n",
    "            data.append({'title': title, 'content': content})\n",
    "\n",
    "    # Step 4: Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'data/knowledge_for_the_time.txt' \n",
    "df = text_to_dataframe_with_titles(file_path)\n",
    "df['content'] = df['content'].str.replace(\"_\", \"\")\n",
    "df['tokens'] = df['content'].apply(lambda text: len(tokenizer.encode(text)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Politics not yet a Science.</td>\n",
       "      <td>Mr. Buckle, in his thoughtful History of Civil...</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Philosopher and the Historian.</td>\n",
       "      <td>“I have read somewhere or other,” says Lord Bo...</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Whig and Tory Ministries.</td>\n",
       "      <td>The domestic history of England during the rei...</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Protectionists.</td>\n",
       "      <td>This name was given to that section of the Con...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Rats, and Ratting.</td>\n",
       "      <td>James, in his Military Dictionary, 1816, state...</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>The Book of Job.</td>\n",
       "      <td>Diversified are the opinions of the most learn...</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Great Precedence Question.</td>\n",
       "      <td>The great question relative to precedence whic...</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>London Review.</td>\n",
       "      <td>CRITICAL OPINIONS OF THE ABOVE WORK.\\n\\n“Anoth...</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Dr. Falck Lebahn’s Popular Series of German Sc...</td>\n",
       "      <td>‘As an educational writer in the German tongue...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Opinions of the Press.</td>\n",
       "      <td>New Book by one of the Contributors to ‘The Re...</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "22                         Politics not yet a Science.   \n",
       "23                  The Philosopher and the Historian.   \n",
       "24                           Whig and Tory Ministries.   \n",
       "25                                     Protectionists.   \n",
       "26                                  Rats, and Ratting.   \n",
       "..                                                 ...   \n",
       "363                                   The Book of Job.   \n",
       "365                         Great Precedence Question.   \n",
       "378                                     London Review.   \n",
       "450  Dr. Falck Lebahn’s Popular Series of German Sc...   \n",
       "496                             Opinions of the Press.   \n",
       "\n",
       "                                               content  tokens  \n",
       "22   Mr. Buckle, in his thoughtful History of Civil...     244  \n",
       "23   “I have read somewhere or other,” says Lord Bo...     575  \n",
       "24   The domestic history of England during the rei...     955  \n",
       "25   This name was given to that section of the Con...     123  \n",
       "26   James, in his Military Dictionary, 1816, state...     176  \n",
       "..                                                 ...     ...  \n",
       "363  Diversified are the opinions of the most learn...    1183  \n",
       "365  The great question relative to precedence whic...    1367  \n",
       "378  CRITICAL OPINIONS OF THE ABOVE WORK.\\n\\n“Anoth...     685  \n",
       "450  ‘As an educational writer in the German tongue...      68  \n",
       "496  New Book by one of the Contributors to ‘The Re...    1226  \n",
       "\n",
       "[328 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[~df['title'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(170945)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[~df['title'].isnull(), 'tokens'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
